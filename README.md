# Agents
这里是AI Agent技术白皮书（Google，2025）的中文版本，目前仍在翻译，鄙人水平有限，若有错误请及时指出，提交issues。下面是正文

备注：agent是代理的意思，AI Agent是自主智能体，通常为了方便读写，Agent也会被称为“智能体”

# 从预测性人工智能到AI Agent（自主智能体）
> 智能体是语言模型的自然演化，并在软件中得到应用。

  人工智能正在发生变革。多年来，人们关注点始终是那些擅长处理被动、离散任务的模型：回答问题、翻译文本或根据提示生成图像。这种范式虽强大，但需要人类在每个步骤中持续指导。如今我们正见证范式转变——人工智能正从单纯预测或生成内容，迈向能够自主解决问题并执行任务的新型软件类别。
  
  这一新领域以AI Agents为核心。Agent并非静态工作流中的简单AI模型，而是具备完整功能的应用程序，能够制定计划并采取行动以达成目标。它融合了语言模型（language model, LM）的推理能力与实际行动能力，从而能够处理单一模型无法应对的复杂、多步骤的任务。其关键能力在于Agent能够自主运作，无需人工全程指导，便能自主推导达成目标所需的后续步骤。

  本文档是五部分系列的第一篇，旨在为开发人员、架构师和产品负责人提供正式指南，帮助他们将概念验证转化为稳健的、生产级代理系统。虽然构建简单原型较为简单，但确保安全性、质量和可靠性却是重大挑战。本文提供全面基础：
  * 核心解剖：将代理分解为三大核心组件：推理模型、可操作工具及管控协调层。
  * 能力分类：将代理从简单的连接问题解决者分类到复杂的协作多代理系统。
  * 架构设计：深入探讨各组件的实际设计考量，涵盖模型选择到工具实现的全流程。
  * 生产构建：建立Agent运维体系，实现从单实例到企业级治理的代理系统评估、调试、安全保障及规模化部署。

  基于之前的[agent白皮书](https://www.kaggle.com/whitepaper-agents)<sup>1</sup>和[agent伴侣](https://www.kaggle.com/whitepaper-agent-companion)<sup>2</sup>，本指南提供了成功构建部署和管理新一代智能应用所需的基础概念与战略框架。这些应用能够通过推理、行动和观察来达到[目标](https://arxiv.org/pdf/2201.11903)<sup>3</sup>

  > 语言难以描述人类与人工智能的交互本质。我们倾向于将人工智能拟人化，使用“思考”、‘推理’、“认知”等人类术语。我们尚未创造出区分“基于语义意义的认知”与“基于最大化奖励函数高概率的认知”的词汇。这两种认知本质不同，但99%以上的情况下结果相同。

# 介绍AI Agents
简而言之，AI agent可定义为由模型、工具、协调层和部署组合而成，通过循环调用语言模型来实现目标。这四个要素构成了任何自主系统的核心架构。
  * 模型（“大脑”）：核心语言模型或基础模型，作为代理的核心推理引擎，负责处理信息、评估选项并作出决策。模型的类型（通用型、微调型或多模态型）决定了代理的认知能力。代理系统是语言模型输入上下文窗口的最终监护人。
  * 工具（“手”）：这些机制将代理的推理能力与外部世界相连，使其能执行超越文本生成的操作。包括API扩展、代码函数及数据存储（如数据库或向量存储），用于获取实时事实信息。代理系统能让语言模型规划工具使用方案，执行工具操作，并将工具结果注入下一次语言模型调用的输入上下文窗口。
  * 协调层（“神经系统”）：该层负责管理代理的运行循环，涵盖规划、记忆（状态）及推理策略执行。通过提示框架与推理技术（如[Chain-of-Thought](https://arxiv.org/pdf/2201.11903)<sup>4</sup>或[ReAct](https://arxiv.org/abs/2210.03629)<sup>5</sup>，将复杂目标分解为步骤，并决定何时进行思考、何时调用工具。同时为Agent提供记忆功能，使其能够“记住”信息。
  * 部署（“身体和腿”）：虽然在笔记本电脑上构建agent程序能有效实现原型开发，但只有投入生产部署才能使其成为可靠且可访问的服务。
这需要将代理部署在安全且可扩展的服务器上，并将其与关键生产服务集成，以实现监控、日志记录和管理功能。部署完成后，用户可通过图形界面访问该代理，其他代理也可通过代理间通信（A2A）API进行程序化访问。

  归根结底，构建生成式AI Agent是开发解决方案以解决任务的一种新方式。传统开发者如同“砌砖工”，需精确定义每个逻辑步骤。而Agent开发者更像导演：不必为每个动作编写显式代码，只需设置场景（指导性指令与提示）、选定演员（工具与API），并提供必要背景（数据）。核心任务转变为引导这个自主“演员”完成预期表演。

  你很快就会发现，语言模型的最大优势——其惊人的灵活性——也正是最令人头疼之处。这种模型无所不能的特性，反而使其难以被可靠且完美地限定在执行某项特定任务上。我们曾称之为“提示工程”、如今称为“上下文工程”的技术，能引导语言模型生成预期输出。每次调用语言模型时，我们需输入指令、事实依据、可用工具、示例、会话历史、用户档案等信息——通过精准填充上下文窗口，获取所需输出。Agent正是管理语言模型输入以完成任务的软件。

  当问题出现时，调试（debugging）变的至关重要。“Agent运维”本质上重新定义了熟悉的测量、分析和系统优化循环。通过追踪和日志，我们可以监控代理的“思维过程”，以识别偏离预期执行路径的情况。随着模型演进与框架升级，开发者的核心职责在于提供关键要素：领域专业知识、明确的人格设定，以及与实用任务执行工具的无缝集成。需谨记：全面评估与测试的结果，往往比初始指令的影响更为重要。

  当Agents被精确配置，配备清晰指令、可靠工具及集成上下文作为记忆库，拥有卓越的用户界面、规划与问题解决能力以及通识世界知识时，它便超越了单纯的“工作流自动化”概念。它开始作为协作实体运作：成为团队中高效、独特适应且能力非凡的新成员。

  >本质上，Agent是专精于上下文窗口管理艺术的系统。它持续循环进行着四步操作：整合上下文、向模型发出指令、观察结果，然后为下一步重新整合上下文。这些上下文可能包含系统指令、用户输入、会话历史、长期记忆、权威来源的知识基础、可用工具清单以及已调用工具的执行结果。这种对模型注意力的精密管理，使其推理能力得以应对新颖情境并达成目标。

# 代理式问题解决过程
  我们已将AI代理定义为一个完整的、以目标为导向的应用程序，集成推理模型、可操作工具和治理协调层。简短版本是“带有工具的LM循环以实现目标”。

  但这个系统究竟如何*运作*？代理从接收到请求到交付结果的整个过程中，具体执行哪些操作？

  本质上，Agent通过持续循环的过程来实现其目标。尽管该循环可能变得极其复杂，但可将其分解为五个基本步骤，具体详见《Agentic System Design》<sup>6</sup>一书：
  1. 获取任务：流程由特定的高层级目标启动。该任务可由用户提供（例如“为团队安排即将召开的会议差旅”），也可由自动化触发器启动（例如“收到一条新的高优先级客户工单”）。
  2. 扫描场景：Agent感知环境以获取上下文信息。这涉及协调层调用可用资源：“用户请求的内容是什么？”“我的短期记忆中有哪些信息？是否已尝试执行此任务？用户上周是否提供过指导？”“我的工具（如日历、数据库或API）能访问哪些资源？”
  3. 深度思考：这是Agent核心的“思考”循环，由推理模型驱动。Agent将**任务**（步骤1）与**场景**（步骤2）进行分析，并制定计划。这并非单一思考，而是推理链条："要预订差旅，我首先需要了解团队成员。我将使用`get_team_roster`工具。接着需通过`calendar_api`查询成员日程。"
  4. 执行行动：协调层执行计划的首个具体步骤。它选择并调用相应**工具**——呼叫API、运行代码函数或查询数据库。这是Agent超越自身内部推理范畴，对外部世界采取行动的环节。
  5. 观察与迭代：Agent观察其行动的结果。`get_team_roster`工具返回包含五个名字的列表。这些新信息被添加到Agent的上下文或“记忆”中。循环随后重复，回到步骤3：“现在我已获取名单，下一步是为这五人查询日历。我将使用`calendar_api`。”
  
  这个“思考、行动、观察”的循环持续进行——由协调层管理，模型进行推理，工具执行操作，直至Agent的内部计划完成且初始任务达成。下面为AI Agent解决问题过程图：
  ![图1：AI Agent解决问题过程](https://github.com/HauUhang/Agents/blob/main/img/Agentic_AI_problem-solving_process.png?raw=true)

  让我们通过一个真实案例，了解客服支持专员如何在以下5步循环中开展工作：

  想象一下一个用户问：“我的订单号12345在哪？”

  Agent不会立即行动，而是先进入“深思熟虑”阶段制定完整策略。它会思考推理出"用户需要查询配送状态。为提供完整答复，我需执行多步计划：
  1. 识别：首先在内部数据库中定位订单，确认其存在并获取详细信息。
  2. 从订单详情中提取物流承运商的追踪号，随后通过外部承运商API查询实时状态。
  3. 反馈：最终将收集的信息整合为清晰有用的用户回复。"
  
  怀揣多步骤计划，Agent开始执行。在首个“执行”阶段，它启动计划第一步，调用`find_order(‘12345’)`工具。系统获取完整订单记录，其中包含追踪号“ZYX987”。

  代理的协调层识别到计划的第一部分已完成，随即进入第二阶段。它通过调用`get_shipping_status(“ZYX987”)`工具执行操作，并观察到新结果：“正在配送中”。

  最后，在成功完成计划中的数据收集阶段后，该代理进入“报告”步骤。它感知到已具备所有必要组件，规划最终消息，并通过生成响应采取行动：“您的订单#12345状态为'正在配送中'！”

# 代理系统分类法
理解五步操作循环是解谜的第一步，第二步是认识到该循环可通过调整复杂度来创建不同类别的代理。对于架构师或产品负责人而言，关键的初始决策在于确定要构建何种类型的代理。

我们可以将代理系统划分为几个广义层级，每个层级都基于前一层级的能力进行构建。
![代理系统五步骤](https://github.com/HauUhang/Agents/blob/main/img/agentic_system_in_5_steps.png?raw=true)

## Level 0: 核心推理系统
  在构建Agent之前，我们必须从最基础的“大脑”形态开始：即推理引擎本身。在此架构中，语言模型（LM）处于孤立运行状态，仅凭海量预训练知识进行响应，不具备任何工具、记忆能力，也无法与实时环境交互。

  其优势在于深度训练赋予的解释能力——既能阐释既定概念，又能制定详尽的解题策略。代价则是完全缺乏实时感知力：对于训练数据之外的事件或事实，它本质上处于“盲视”状态。
  
例如它能阐述职业棒球规则及纽约洋基队的完整历史，但若询问“昨晚洋基队比赛最终比分？”则无法作答——该赛事作为训练数据收集后发生的具体现实事件，其信息根本不存在于模型知识库中。

## Level 1: 互联的解决者
  在此层级，推理引擎通过连接并利用外部工具——即我们架构中的“手”组件——成为功能型Agent。其问题解决能力不再局限于静态预训练知识。

  借助五步循环机制，Agent可解答先前问题。面对“任务”：“昨晚洋基队比赛最终比分是多少？”，其“思考”步骤识别出这是实时数据需求。随后“行动”步骤调用工具（如带日期和关键词的谷歌搜索API），“观察”搜索结果（例如”洋基队5-3获胜"），并将该事实整合为最终答案。

这种与世界交互的基础能力——无论是通过搜索工具获取比分、借助金融API获取实时股价，还是通过检索增强生成（RAG）调用数据库——正是1级Agent的核心能力。

## Level 2: 战略问题解决者
  第二级标志着能力的显著扩展，从执行简单任务转向战略性规划复杂的多阶段目标。此阶段涌现的核心技能是上下文工程：Agent主动筛选、整合并管理计划各阶段最相关信息的能力。

  Agent的准确性取决于聚焦的高质量情境。上下文工程通过精心管理模型有限的注意力，防止信息过载并确保高效运行。
  
  例如，考虑以下“任务”：“**在位于山景城圆形剧场大道1600号的办公室与旧金山市场街1号客户办公室的中间位置，寻找一家优质咖啡馆。**”

  二级代理将开始制定计划：
  1. **思考**：“我必须先找到中点。”
    • **行动**：调用`地图`工具输入两地地址。
    • **观察**：“中点是加州米尔布雷市。”
  2. 思考：“现在要查找米尔布雷市的咖啡馆。用户要求'优质'店铺，因此将筛选四星及以上评分的场所。”
    • **行动**：调用`google_places`工具，查询条件为`query="coffee shop in Millbrae, CA",min_rating=4.0.`(最低评分4.0)（此为上下文工程——系统自动将前一步输出转化为精准搜索查询）
    • **观察**：“检索结果显示'Millbrae Coffee'和'The Daily Grind'。”
  3. 思考：“我将整合这些结果并呈现给用户。”
   
  这种战略规划还能实现主动辅助，例如当代理读取冗长的航班确认邮件时，会提取关键上下文（航班号、日期），并主动将其添加至你的日历。

## Level 3: 协作多代理系统
  在最高层级，范式发生了彻底转变。我们不再致力于构建单一的全能型“超级代理”，而是转向由“专家团队”协同运作的模式——这种模式直接映射了人类组织结构。系统的集体力量正源于这种分工协作。

  在此，Agent将其他Agent视为工具。设想“项目经理”Agent接到一项“任务”：“发布新款'Solaris'耳机”。项目经理Agent不会亲自完成全部工作。它通过为专业化Agents团队创建新任务来执行工作，其运作方式与现实生活中的项目管理如出一辙：
  1. 市场研究Agent任务：“分析降噪耳机的竞争对手定价策略。请于明日提交分析报告。”
  2. 营销Agent任务：“以'Solaris'产品规格表为依据，起草三版新闻稿。”
  3. web开发Agent任务：“根据附件中的设计稿生成新产品页面的HTML代码。”

  这种协作模式虽然目前受限于当今语言模型的推理能力，但代表着从头到尾自动化处理整个复杂业务流程的前沿技术。

## Level 4: 自我进化系统
  第四级标志着从任务分派到自主创造与适应的重大飞跃。在此阶段，智能系统能够识别自身能力缺口，并动态创建新工具甚至新代理来填补空白。它从使用固定资源集转向主动拓展资源边界。

以我们的示例而言，负责“Solaris”项目启动的“项目经理”Agent可能意识到需要监测社交媒体舆论，但其团队中尚无此类工具或代理存在。

  1. **思考（Meta-Reasoning, 元推理）**：“我必须追踪社交媒体上关于'Solaris'的热议，但自身能力不足。”
  2. **行动（自主创建）**：系统未选择失败，而是调用高级AgentCreator工具执行新任务：“创建新代理，监控社交媒体中'Solaris耳机'关键词，执行情感分析并提交每日摘要报告。”
  3. **观察**：全新专业化情绪分析代理即时创建、测试并加入团队，随时准备参与原始任务。

  这种动态扩展自身能力的自主性，使Agents团队蜕变为真正具备学习与进化能力的组织。

# 核心代理架构：模型、工具和协调
我们知道代理的功能以及它的扩展方式。但我们究竟该如何*构建*它呢？从概念到代码的转变，关键在于其三个核心组件的具体架构设计。

## 模型：你的AI Agent的大脑
语言模型是Agent推理的核心，其选择是决定Agent认知能力、运行成本和速度的关键架构决策。然而，若将此选择简单视为挑选基准测试得分最高的模型，往往是通向失败的捷径。Agent在生产环境中的成功，很少取决于通用学术基准测试。

现实世界成功需要一个擅长**代理基础**的模型：卓越**推理**来导航复杂、多步问题，并能可靠运用工具与[世界](https://arxiv.org/abs/2406.12045)<sup>7</sup>交互。

要实现这一目标，需先定义业务问题，再通过直接映射该结果的指标测试模型。若Agent需编写代码，请在私有代码库中测试；若处理保险理赔，则评估其从特定文档格式中提取信息的能力。此类分析还需与成本和延迟等实际因素交叉验证。所谓“最佳”模型，实为在质量、速度与成本三者间找到最优平衡点的[解决方案](https://artificialanalysis.ai/guide)<sup>8</sup>。

您可能选择不止一个模型，一个“专家团队”。您不会用大锤砸核桃。健壮的代理架构可能使用像**Gemini 2.5 Pro**这样的前沿模型进行初始规划和复杂推理的重任，但然后智能地将更简单、高容量的任务——如分类用户意图或总结文本——路由到更快、更具成本效益的模型，如**Gemini 2.5 Flash**。模型路由可能自动或硬编码，但它是优化[性能和成本](https://docs.cloud.google.com/vertex-ai/generative-ai/docs?hl=zh-cn)<sup>9</sup>的关键策略。

相同的原则适用于处理多样数据类型。虽然像[Gemini live mode](https://gemini.google/overview/gemini-live/)<sup>10</sup>这样的本地多模态模型提供处理图像和音频的简化路径，但替代方案是使用专用的工具，如[Cloud Vision API](https://cloud.google.com/vision?e=48754805&hl=en])<sup>11</sup>或[Speech-to-Text API](https://cloud.google.com/speech-to-text?e=48754805&hl=en)<sup>12</sup>。在这种模式中，世界首先转换为文本，然后传递给仅语言模型进行推理。这增加了灵活性，并允许最佳组件，但也引入了显著复杂性。

最后，人工智能领域正处于持续快速演进的状态。今天选择的模型，半年后就会被取代。“设置后置之不理”的心态已难以维系。适应这种现实需要构建敏捷的运营框架——即“智能体运维”[实践](https://medium.com/google-cloud/genaiops-operationalize-generative-ai-a-practical-guide-d5bedaa59d78)<sup>13</sup>。通过强大的持续集成/持续交付管道，持续根据关键业务指标评估新模型，既能降低升级风险又能加速迭代，确保Agent始终搭载最优“大脑”，而无需彻底改造架构。

## 工具：你的AI Agent的手
若模型是Agent的头脑，工具便是连接其推理与现实的双手。它们使Agent能够突破静态训练数据的局限，实时获取信息并在现实世界中采取行动。一个强大的工具接口包含三个环节：定义工具的功能、调用工具，以及观察结果。

以下是Agent构建者将为其代理配备的主要工具类型。如需更全面的深入解析，请参阅本系列中专注于代理工具的白皮书。

## 检索信息：扎根于现实
最基础的工具是访问最新信息的能力。**检索增强生成（RAG）**给代理一个“图书馆卡”来查询外部知识，通常存储在**向量数据库**或**知识图谱**中，从内部公司文档到通过Google搜索的网络知识。对于结构化数据，**自然语言到SQL (NL2SQL)** 工具允许代理查询数据库来回答分析问题，如，“我们上季度最畅销的产品是什么？” 通过在说话前查找事物——无论是在文档还是数据库中——代理将自己扎根于事实，大幅减少幻觉。

## 执行行动：改变世界
代理的真正力量在它们从读取信息转向主动做事时释放。通过将现有**API**和代码函数包装为工具，代理可以发送电子邮件、安排会议，或在ServiceNow中更新客户记录。对于更动态的任务，代理可以**即时编写并执行代码**。在安全的沙箱中，它可以生成SQL查询或Python脚本来解决复杂问题或执行计算，将其从知识丰富的助手转变为[自主行动者](https://cloud.google.com/agent-builder/agent-engine/code-execution/overview)<sup>14</sup>。

这还包括人类交互的工具。代理可以使用**Human in the Loop (HITL)**工具来暂停其工作流并请求确认（例如，`ask_for_confirmation()`）或从用户界面请求特定信息（例如，`ask_for_date_input()`），确保人在关键决策中参与。HITL可以通过SMS文本消息和数据库中的任务实现。

## 函数调用：将工具连接到您的Agent
为了代理可靠地进行“函数调用”并使用工具，它需要清晰的指令、安全连接和[协调](https://ai.google.dev/gemini-api/docs/function-calling?example=meeting&hl=zh-cn)<sup>15</sup>。。长期标准如**OpenAPI**规范提供这一点，给Agent一个结构化合同，描述工具的目的、其所需参数及其预期响应。这个模式让模型每次生成正确的函数调用并解释API响应。对于更简单的发现和工具连接，开放标准如**Model Context Protocol (MCP)**变得流行，因为它们更[方便](https://github.com/modelcontextprotocol/)<sup>16</sup>。此外，一些模型有本地工具，如带有本地Google搜索的Gemini，其中函数调用作为LM调用[本身](https://ai.google.dev/gemini-api/docs/google-search?hl=zh-cn)<sup>17</sup>的一部分发生。

## 协调层
如果模型是Agent的大脑，工具是它的双手，协调层是连接它们的中央神经系统。它是运行“思考、行动、观察”循环的引擎，是治理代理行为的状态机，是开发人员精心制作的逻辑活起来的地方。这一层不仅仅是管道；它是整个代理交响乐的指挥，决定模型何时应该推理，哪个工具应该行动，以及行动的结果如何告知下一个动作。

## 核心设计选择
首个架构决策是确定Agent的自主程度。这种选择存在于一个连续谱上：一端是确定性、可预测的工作流，将语言模型作为特定任务的工具——如同在现有流程中添加少量人工智能进行增强；另一端则是让语言模型掌控全局，通过动态适应、规划和执行任务来达成目标。

一个并行的选择是实现方法。无代码构建者提供速度和可访问性，使业务用户能够自动化结构化任务并快速构建简单Agent。对于更复杂、任务关键的系统，代码优先框架，如**Google的[代理开发套件（ADK）](https://google.github.io/adk-docs/)**<sup>18</sup>，提供工程师所需深入控制、可定制性和集成能力。

无论采用哪种方法，生产级框架是必不可少的。它必须是**开放**的，允许插入任何模型或工具以防止供应商锁定。它必须提供精确控制，启用混合方法，其中LM的非确定性推理由硬编码业务规则治理。最重要的是，框架必须为**可观察性**而构建。当代理行为异常时，您不能简单地在模型的“想法”中放置断点。鲁棒框架生成详细跟踪和日志，暴露整个推理轨迹：模型的内部独白、它选择的工具、它生成的参数，以及它观察到的结果。

## 用领域知识和角色指导
在这一框架内，开发人员最强大的杠杆是用领域知识和独特角色指导代理。这通过系统提示或一组核心指令实现。这不仅仅是一个简单命令；它是代理的宪法。

在这里，您告诉它，`您是Acme Corp的有帮助客户支持代理，... `并提供约束、期望输出模式、参与规则、特定语调，以及何时以及为什么应该使用其工具的明确指导。指令中的几个示例场景通常非常有效。

## 用上下文增强
Agent的“内存”在运行时被协调到LM上下文窗口中。对于更完整的深入探讨，请参阅本系列中专注代理内存的白皮书。

短期内存是代理的活动“草稿本”，维护当前对话的运行历史。它跟踪正在进行的循环中的（行动、观察）对序列，提供模型决定下一步做什么的即时上下文。这可能被实现为像状态、工件、会话或线程这样的抽象。

长期内存提供跨会话的持久性。从架构上讲，这几乎总是作为另一个专用工具实现——连接到向量数据库或搜索引擎的RAG系统。协调器赋予代理预取和主动查询其自身历史的能力，允许它“记住”用户的偏好或几周前类似任务的结果，以获得真正个性化和连续[体验](https://google.github.io/adk-docs/sessions/memory/)。<sup>19</sup>

## 多代理系统和设计模式
随着任务复杂性的增长，构建单个、全能的“超级代理”变得低效。更有效的解决方案是采用“专家团队”方法，这镜像人类组织。这是**多代理系统**的核心：复杂过程被分割为离散子任务，每个分配给专用的、专业的AI代理。这种分工允许每个代理更简单、更专注、更易构建、测试和维护，这对动态或长期运行的业务过程理想。

架构师可能依赖于经过验证的代理设计模式，虽然代理能力从而模式正在快速[演变](https://docs.cloud.google.com/architecture/choose-design-pattern-agentic-ai-system?hl=zh-cn)。 <sup>20</sup>对于动态或非线性任务，**协调器**模式是必不可少的。它引入一个“经理”代理，分析复杂请求、分割主要任务，并智能地将每个子任务路由到适当的专家代理（如研究员、作家或编码员）。协调器然后聚合每个专家的响应，以制定最终、全面的答案。下图来自以下[链接](cloud.google.com/architecture/choose-design-pattern-agentic-ai-system)的“迭代改进”模式：
![迭代改进](https://github.com/HauUhang/Agents/blob/main/img/iterative_refinement.png?raw=true)

对于更线性工作流，**顺序**模式更合适，像数字装配线，其中一个代理的输出成为下一个的直接输入。其他关键模式关注质量和安全。**迭代细化**模式创建反馈循环，使用“生成器”代理创建内容和“批评者”代理根据质量标准评估它。对于高风险任务，**Human-in-the-Loop (HITL)**模式是关键的，在代理采取重大行动前创建故意暂停以从人获取批准。

## 代理部署和服务
在您构建本地Agent后，您希望将其部署到服务器上，在那里它一直运行，其他人和代理可以使用它。继续我们的比喻，部署和服务将是代理的身体和腿。代理需要几个服务才能有效，会话历史和内存持久性等。作为代理构建者，您还将负责决定记录什么，以及为数据隐私和数据驻留以及法规合规采取什么安全措施。所有这些服务在部署代理到生产时都在范围内。

幸运的是，代理构建者可以依赖于数十年应用程序托管基础设施。代理毕竟是一种新形式的软件，许多相同的原则适用。构建者可以依赖于专为代理设计的部署选项，如**Vertex AI Agent Engine**，它支持运行时和一切都在一个[平台](https://cloud.google.com/agent-builder/agent-engine/overview)<sup>21</sup>
对于希望更直接控制其应用程序栈的软件开发人员，或在现有DevOps基础设施中部署代理，任何代理和大多数代理服务都可以添加到docker容器中，并部署到行业标准运行时，如[Cloud Run或GKE](cloud.google.com/kubernetes-engine/docs/concepts/gke-and-cloud-run)<sup>22</sup>。

下图是[Vertex AI 代理构建器](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)
![Vertex AI 代理构建器](https://github.com/HauUhang/Agents/blob/main/img/vertex_AI_Agent_builder.png?raw=true)

如果您不是软件开发人员和DevOps专家，部署您的第一个代理的过程可能令人生畏。许多代理框架通过部署命令或专用平台使这变得容易，这些应该用于早期探索和入门。提升到安全和生产就绪环境通常需要更大的时间投资和最佳实践的应用，包括[您的代理](https://github.com/GoogleCloudPlatform/agent-starter-pack)<sup>23</sup>的CI/CD和自动化测试。

## 代理操作：应对不可预测性的结构化方法
当你第一次创建Agent时，你将反复手动测试其行为表现。新增的功能是否正常运作？修复漏洞时是否引发了其他问题？测试在软件开发中司空见惯，但在生成式人工智能领域却有着截然不同的运作模式。

从传统、确定性软件到随机、代理系统的转变需要新的操作哲学。传统软件单元测试可以简单地断言`输出 == 预期`；但当代理的响应在设计上是概率性的时，这不起作用。而且，因为语言复杂，它通常需要LM来评估“质量”——代理的响应做了它应该做的所有事，没有它不应该做的，并带有适当的语调。下图是[DevOps、MLOps和GenAIOps的操作领域之间关系](https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0)
![DevOps、MLOps和GenAIOps的操作领域之间关系](https://github.com/HauUhang/Agents/blob/main/img/relationships.png?raw=true)

代理操作是对这种新现实的纪律化、结构化方法。它是DevOps和MLOps的自然演变，针对构建、部署和管理AI Agent的独特挑战量身定制，将不可预测性从责任转变为管理的、可衡量的、可靠的功能<sup>24</sup>。对于更完整的深入探讨，请参阅本系列中专注代理质量的白皮书。

## 衡量重要的事项：像A/B实验一样仪表成功
在能改进代理之前，必须在业务上下文中定义“更好”意味着什么。进行可观察性策略框架化为A/B测试，并问自己：证明代理交付价值的Key Performance Indicators (KPIs)是什么？这些指标应该超越技术正确性，并衡量现实世界影响：目标完成率、用户满意度分数、任务延迟、每个交互的操作成本，以及——最重要的是——对业务目标的影响，如收入、转换或客户保留。这种自上而下的观点将指导您的其余测试，将您置于指标驱动开发的路径上，并让您计算投资回报。

## 质量而非通过/失败：使用LM评判
业务指标不会告诉代理是否正确行为。由于简单通过/失败是不可能的，我们转向使用“LM作为评判”评估质量。这涉及使用强大模型根据预定义标准评估代理的输出：它给出了正确答案吗？响应是事实基础的吗？它遵循指令了吗？这种自动化评估，对着一个黄金提示数据集运行，提供一致的质量衡量。

创建评估数据集——包括理想（或“黄金”）问题和正确响应——可能是一个繁琐的过程。要构建这些，应该从代理的现有生产或开发交互中采样场景。数据集必须覆盖期望用户参与的全部用例范围，加上一些意外的。虽然在评估中的投资很快就会回报，但评估结果应该总是由领域专家审查，然后才被接受为有效。随着领域专家的支持，这些评估的整理与维护正日益成为产品经理的核心职责。

## 指标驱动开发：你的部署通过/不通过
当您自动化了数十个评估场景并建立了可信赖的质量评分体系后，便可自信地测试开发代理的变更。流程十分简单：将新版本应用于完整评估数据集，直接对比其评分与现有生产版本。这个稳健的系统消除了猜测成分，确保您对每次部署都充满信心。尽管自动化评估至关重要，但切勿忽视延迟、成本和任务成功率等其他关键因素。为实现最高安全性，请采用
A/B部署策略逐步推出新版本，并将这些真实生产环境指标与模拟评分进行对照分析。

## 使用OpenTelemetry跟踪调试：回答“为什么？”
当指标下降或用户报告错误时，您需要弄清“原因”。
OpenTelemetry追踪记录是代理程序完整执行路径（轨迹）的高保真逐步记录，可用于调试[代理程序的每个步骤](https://opentelemetry.io/blog/2025/ai-agent-observability/)。<sup>25</sup>通过追踪记录，您能清晰看到：发送给模型的具体提示、模型内部推理过程（若可获取）、模型调用的具体工具、为该工具生成的精确参数，以及作为观察结果返回的原始数据。初次查看时追踪记录可能显得复杂，但它们提供了诊断和修复任何问题根本原因所需的细节。重要追踪细节可转化为指标，但审查追踪记录主要用于调试而非性能概览。追踪数据可在Google Cloud Trace等平台无缝收集，这些平台能可视化并搜索海量追踪记录，从而简化根本原因分析流程。

## 珍惜人类反馈：指导你的自动化
人类反馈不是需要处理的烦恼，它是改进代理的最有价值和数据丰富资源。当用户提交错误报告或点击“ thumbs down”按钮时，他们在给你礼物：一个新的、现实世界的边缘案例，您的自动化评估场景错过了。收集和聚合这些数据是关键的；当你看到类似报告或指标下降的统计显著数量时，你必须将发生事件追溯到您的分析平台，以生成洞见并触发操作问题的警报。有效的代理操作过程通过捕获此反馈、复制问题，并将该特定场景转换为评估数据集中的新永久测试案例“关闭循环”。这确保您不仅修复错误，还为系统接种，防止整个错误类别再次发生。

## Agent互操作性
一旦构建了高质量Agent，你希望能够将它们与用户和其他Agent互连。在我们的身体部位比喻中，这将是Agent的脸。与连接代理不同，连接代理与数据和API；[代理不是工具](https://discuss.google.dev/t/agents-are-not-tools/192812)。让我们假设已经将工具连接到您的代理，现在让我们考虑如何将您的代理带入更广泛的生态系统。<sup>26</sup>

## Agent和人类
代理-人类交互的最常见形式是通过用户界面。在其最简单形式中，这是一个聊天机器人，用户输入请求，代理作为后端服务处理它并返回文本块。更先进的代理可以提供结构化数据，如JSON，来驱动丰富、动态的前端体验。Human in the loop (HITL)交互模式包括意图细化、目标扩展、确认和澄清请求。

计算机使用是一类工具，其中LM控制用户界面，通常带有人类交互和监督。启用计算机使用的代理可以决定下一个最佳行动是导航到新页面、突出特定按钮，或用[相关信息](https://arxiv.org/abs/2310.03691)<sup>27</sup>预填充表单。

代理不是代表用户使用界面，LM可以改变UI以满足时刻的需求。这可以通过控制UI的工具[（MCP UI）](https://mcpui.dev/)<sup>28</sup>，或可以与代理同步客户端状态的专用UI消息系统[（AG UI）](https://docs.ag-ui.com/introduction)<sup>29</sup>，甚至定制接口的生成[（A2UI）](https://github.com/google/A2UI)<sup>30</sup>来完成。

当然，人类交互不限于屏幕和键盘。高级代理正在打破文本障碍，并转向实时、多模态通信，“live mode”创建更自然、人类般的连接。像[Gemini Live API]()<sup>31</sup>这样的技术启用双向流式传输，允许用户与代理对话并中断它，就像在自然对话中一样。

这种能力从根本上改变了代理-人类协作的性质。通过访问设备的摄像头和麦克风，代理可以看到用户看到的东西并听到他们说的东西，以人类对话的延迟用生成的语音响应。

这开辟了文本无法实现的广泛用例，从技术人员在修理设备时接收免提指导，到购物者获取实时风格建议。它使代理成为更直观和可访问的伙伴。

## Agents和Agents
正如代理必须与人类连接，它们也必须彼此连接。随着企业扩展AI的使用，不同团队将构建不同的专业代理。没有共同标准，连接它们将需要构建脆弱的、自定义API集成的纠缠网络，无法维护。核心挑战是双重的：发现（我的代理如何找到其他代理并知道它们能做什么？）和通信（我们如何确保它们说相同的语言？）。

**Agent2Agent (A2A)协议**是设计用于解决这个问题的开放标准。它作为代理经济学的通用握手。A2A允许任何代理发布数字“名片”，称为Agent Card。这个简单的JSON文件广告代理的能力、其网络端点，以及与之交互所需的安全凭据。这使发现简单且标准化。与专注于解决事务请求的MCP相反，代理2代理通信通常用于额外的问题解决。

一旦发现，代理使用面向任务的架构进行通信。不是简单的请求-响应，交互被框架为异步“任务”。客户端代理向服务器代理发送任务请求，然后服务器代理可以在长期连接上提供流式更新，因为它在问题上工作。这种鲁棒、标准化的通信协议是谜题的最后一块，启用协作的、3级多代理系统，代表自动化前沿。A2A将孤立的代理集合转变为真正的、互操作的生态系统。

## Agent和成本
随着AI Agent为我们做更多任务，其中一些任务涉及买卖、谈判或促进交易。当前的网络是为人类点击“购买”构建的，责任在人类身上。如果自治代理点击“购买”，它会创建信任危机——如果出错，谁的责任？这些是授权、真实性和问责的复杂问题。要解锁真正的代理经济，我们需要新标准，允许代理安全可靠地代表其用户交易。

这个新兴领域远未确立，但两个关键协议正在铺平道路。**Agent Payments Protocol (AP2)**是一个开放协议，设计为代理商务的最终语言。它通过引入加密签名的数字“授权”扩展像A2A这样的协议。这些作为用户意图的可验证证明，为每个交易创建不可否认的审计轨迹。这允许代理基于用户委托的权限安全浏览、谈判和全球交易。补充这一点的是**x402**，一个开放互联网支付协议，使用标准HTTP 402“支付所需”状态码。它启用无摩擦的、机器对机器微支付，允许代理在按使用付费的基础上为API访问或数字内容付费，而无需复杂账户或订阅。这些协议共同构建代理网络的基础信任层。

## 保护单个Agent：信任权衡
当您创建您的第一个AI代理时，您立即面临一个基本紧张关系：效用和安全之间的权衡。要使代理有用，您必须赋予它权力——做出决策的自治和执行行动的工具，如发送电子邮件或查询数据库。然而，您赋予的每一盎司权力都引入相应的风险度量。主要安全问题是**流氓行动**——无意或有害行为——
和**敏感数据泄露**。您想给您的代理足够长的绳子来做其工作，但足够短以防止它跑进交通，特别是当交通涉及不可逆转行动或您公司的私人数据时<sup>32</sup>。

要管理这一点，您不能仅仅依赖AI模型的判断，因为它可以通过像[提示注入](https://simonwillison.net/series/prompt-injection/)<sup>33</sup>这样的技术操纵。相反，最佳实践是混合、[深度防御方法](https://storage.googleapis.com/gweb-research2023-media/pubtools/1018686.pdf)<sup>34</sup>。第一层由**传统、确定性护栏**组成——一组硬编码规则，作为模型推理之外的安全瓶颈。这可能是一个策略引擎，阻止任何超过100美元的购买，或在代理与外部API交互前要求明确用户确认。这一层为代理的权力提供可预测、可审计的硬限制。

第二层利用**基于推理的防御**，使用AI来帮助保护AI。这涉及训练模型更具抵抗攻击的能力（对抗训练）和采用更小、专业的“守卫模型”，像安全分析师一样行动。这些模型可以在代理的拟议计划执行前检查它，标记潜在风险或违反政策的步骤以供审查。这种混合模型，结合代码的刚性确定性和AI的上下文意识，为即使单个代理创建鲁棒安全姿态，确保其权力始终与目的一致。

## 代理身份：一种新的主体类别
在传统安全模型中，有可能使用OAuth或SSO的人类用户，以及使用IAM或服务账户的服务。代理添加了第三类主体。代理不仅仅是一段代码；它是一个自治行动者，一种新的主体，需要自己的可验证身份。正如员工被发放ID徽章一样，平台上的每个代理必须被发放安全、可验证的“数字护照”。这个代理身份不同于调用它的用户身份和构建它的开发人员身份。这是我们必须在企业中接近身份和访问管理（IAM）的根本转变。

让每个身份得到验证，并为所有身份拥有访问控制，是代理安全的基础。一旦代理拥有加密可验证身份（通常使用像[SPIFFE]()<sup>35</sup>这样的标准），它可以被授予自己的特定、最小特权权限。SalesAgent被授予CRM的读/写访问，而`HRonboardingAgent`被明确拒绝。这种粒度控制是关键的。它确保即使单个代理被入侵或行为异常，潜在爆炸半径也被包含。没有代理身份结构，代理无法以有限委托权限代表人类工作。

`表1：不同行动者类别的非穷举示例，用于认证`

| 主体实体   		    | 认证/验证		   | 注释			  					|
| ----------------- | ---------------- | ---------------------------------- |
| 用户      			| 使用OAuth或SSO认证 | 人类行动者，具有完全自治和对其行动的责任	|
| Agents(主体的新类别)	| 使用SPIFFE验证	   | Agent具有委托权限，代表用户采取行动		|
| 服务账户   			| 集成到IAM 		   | 应用程序和容器，完全确定性，无行动责任		|

## 约束访问的政策
策略是一种授权（AuthZ）形式，与认证（AuthN）不同。通常，策略限制主体的能力；例如，“营销中的用户只能访问这些27个API端点，并且不能执行DELETE命令。”当我们开发代理时，我们需要将权限应用到代理、它们的工具、其他内部代理、它们可以共享的上下文，以及远程代理。想想这样：如果您将所有API、数据、工具和代理添加到你的系统中，那么必须将访问限制为仅那些完成其工作所需的能力子集。这是推荐的方法：在保持[上下文相关](https://openreview.net/pdf?id=l9rATNBB8Y)<sup>36</sup>的同时应用最小特权原则。

## 保护ADK代理
有了身份和策略的核心原则确立，使用代理开发套件（ADK）构建的代理的安全成为通过代码和[配置](https://google.github.io/adk-docs/safety/)<sup>37</sup>应用这些概念的实际练习。

如上所述，该过程需要身份的清晰定义：用户账户（例如OAuth）、服务账户（运行代码）、代理身份（使用委托权限）。一旦认证处理完毕，下一层防御涉及建立策略来约束对服务的访问。这通常在API治理层完成，与支持MCP和A2A服务的治理一起。

下一层是将护栏构建到您的工具、模型和子代理中以强制执行策略。这确保无论LM推理什么或恶意提示可能建议什么，工具自己的逻辑将拒绝执行不安全或违反政策的行动。这种方法提供可预测和可审计的安全基线，将抽象安全策略转化为[具体、可靠的代码](https://google.github.io/adk-docs/callbacks/design-patterns-and-best-practices/#guardrails-policy-enforcement)。<sup>38</sup>

对于可以适应代理运行时行为的更动态安全，ADK提供**回调和插件**。一个`before_tool_callback`允许你在工具运行前检查工具调用的参数，根据代理当前状态验证它们以防止错位行动。对于更可重用的策略，您可以构建插件。一个常见模式是“Gemini作为评判”<sup>39</sup>，使用快速、廉价的模型如Gemini Flash-Lite或您自己的微调Gemma模型来实时筛选用户输入和代理输出，以检测提示注入或有害内容。

对于偏好完全管理、企业级解决方案的组织，用于这些动态检查的**Model Armor**可以作为可选服务集成。Model Armor作为一个专用安全层，筛选提示和响应以应对广泛威胁，包括提示注入、越狱尝试、敏感数据（PII）泄露和[恶意URL](cloud.google.com/security-command-center/docs/model-armor-overview)<sup>40</sup>。通过将这些复杂安全任务卸载到专用服务，开发人员可以确保一致、鲁棒保护，而无需自己构建和维护这些护栏。ADK内的这种混合方法——结合强大身份、工具内确定性逻辑、动态AI驱动护栏，以及像Model Armor这样的可选管理服务——就是您构建既强大又可信的单个代理的方式。下图是[安全和Agent](https://saif.google/focus-on-agents)
![安全和Agent](https://github.com/HauUhang/Agents/blob/main/img/security_and_agents.png?raw=true)

## 从单个Agent扩展到企业舰队
单个AI Agent的生产成功是一个胜利。扩展到数百个舰队是一个架构挑战。如果您正在构建一两个代理，您的主要关注是安全。如果您正在构建许多代理，您必须设计系统来处理更多。正如API蔓延，当代理和工具在组织中扩散时，它们创建一个新的、复杂的交互网络、数据流和潜在安全漏洞。管理这种复杂性需要更高阶治理层，将所有身份和策略集成到中央控制平面中。

## 安全和隐私：强化Agent前沿
企业级平台必须解决生成式AI固有的独特安全和隐私挑战，即使只有一个代理在运行。代理本身成为一个新攻击向量。恶意行动者可以尝试**提示注入**来劫持代理的指令，或**数据投毒**来破坏它用于训练或RAG的信息。而且，约束不当的代理可能无意中在其响应中泄露敏感客户数据或专有信息。

鲁棒平台提供深度防御策略来缓解这些风险。它从数据开始，确保企业的专有信息从未用于训练基础模型，并通过像VPC服务控制这样的控制保护。它需要输入和输出过滤，像防火墙一样用于提示和响应。最后，平台必须提供合同保护，如知识产权赔偿，用于训练数据和生成的输出，给企业部署代理所需的法律和技术信心。

## Agent治理：控制平面而非蔓延
随着代理及其工具在组织中扩散，它们创建一个新的、复杂交互网络和潜在漏洞，这种挑战通常称为“代理蔓延”。管理这需要超越保护单个代理，转向实现更高阶架构方法：一个中央网关，作为所有代理活动的控制平面。

想象一个繁忙的大都市，有数千辆自治车辆——用户、代理和工具——都带着目的移动。没有交通灯、车牌和中央控制系统，混乱将主宰。网关方法创建那个控制系统，建立所有代理交通的强制入口点，包括用户到代理提示或UI交互、代理到工具调用（通过MCP）、代理到代理协作（通过A2A），以及直接推理请求到LM。通过坐在这个关键交叉点，组织可以检查、路由、监控和管理每个交互。

这个控制平面服务两个主要、互连的功能：
1. **运行时策略执行**：它作为实现安全的架构瓶颈。它处理认证（“我知道这个行动者是谁吗？”）和授权（“他们有权限做这个吗？”）。集中执行提供可观察性的“单一玻璃窗”，为每个交易创建常见日志、指标和跟踪。这将分散的代理和工作流意大利面条转变为透明和可审计的系统。

2. **集中治理**：要有效执行策略，网关需要真相来源。这由中央注册表提供——代理和工具的企业应用商店。这个注册表允许开发人员发现和重用现有资产，防止冗余工作，同时给管理员一个完整库存。更重要的是，它启用代理和工具的正式生命周期，允许在发布前进行安全审查、版本控制，以及创建细粒度策略，规定哪些业务单元可以访问哪些代理。

通过将运行时网关与中央治理注册表结合，组织将混乱蔓延的风险转变为管理的、安全的、高效生态系统。

## 成本和可靠性：基础设施基础
最终，企业级代理必须既可靠又具成本效益。一个经常失败或提供缓慢结果的代理有负ROI。相反，一个禁止性昂贵的代理无法扩展以满足业务需求。底层基础设施必须设计来管理这种权衡，安全并遵守法规和数据主权。

在某些情况下，您需要的功能是scale-to-zero（归零），当您对特定代理或子功能有不规则流量时。对于任务关键、延迟敏感的工作负载，平台必须提供专用、保证容量，如LM服务的[Provisioned Throughput](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview?hl=zh-cn)<sup>41</sup>或像[Cloud Run](https://cloud.google.com/run/sla?e=48754805&hl=en)<sup>42</sup>这样的运行时的99.9%服务水平协议（SLA）。这提供可预测的性能，确保您最重要的代理即使在重负载下也始终响应。通过提供这种基础设施选项谱系，加上成本和性能的全面监控，您为将AI代理从有前景的创新扩展为核心、可靠的企业组件建立了最终、必不可少的基础。

## Agent是如何进化并学习
部署在真实世界中的代理在动态环境中运行，其中策略、技术和数据格式不断变化。没有适应能力，代理的性能将随着时间退化——一个过程通常称为“老化”——导致效用和信任的丧失。手动更新大型代理舰队以跟上这些变化是不经济的且缓慢的。更可扩展的解决方案是设计可以自治学习和进化的代理，以[最小工程努力](https://github.com/CharlesQ9/Self-Evolving-Agents)<sup>43</sup>在工作中改善其质量。

## Agent如何学习和自我进化
就像人类一样，Agent从经验和外部信号中学习。这个学习过程由几个信息来源驱动：
* **运行时经验**： 代理从运行时工件中学习，如会话日志、跟踪和内存，这些捕捉成功、失败、工具交互和决策轨迹。至关重要的是，这包括Human-in-the-Loop (HITL)反馈，提供权威更正和指导。
* **外部信号**： 学习也由新外部文档驱动，如更新的企业策略、公共监管指南，或来自其他代理的批评。

然后这个信息用于优化代理的未来行为。先进系统不是简单总结过去交互，而是创建可泛化工件来指导未来任务。最成功的适应技术分为两个类别：
* **增强上下文工程**： 系统不断细化其提示、少样本示例，以及从内存检索的信息。通过为每个任务优化提供给LM的上下文，它增加成功的可能性。
* **工具优化和创建**： 代理的推理可以识别其能力的差距并采取行动填补它们。这可能涉及获得新工具的访问、在飞行中创建新工具（例如，Python脚本），或修改现有工具（例如，更新API模式）。

额外的优化技术，如动态重新配置多代理设计模式或使用人类反馈的强化学习（RLHF），是活跃的研究领域。

示例：学习新合规指南
考虑一个在高度监管行业如金融或生命科学中运行的企业代理。其任务是生成必须遵守隐私和监管规则（例如，GDPR）的报告。

这可以使用多代理工作流实现：
1. 一个**查询Agent**响应用户请求检索原始数据。
2. 一个**报告Agent**将此数据合成到草稿报告中。
3. 一个**批评Agent**，配备已知合规指南，审查报告。如果遇到歧义或需要最终签发，它升级到人类领域专家。
4. 一个**学习Agent**观察整个交互，特别注意来自人类专家的更正反馈。然后它将此反馈泛化为新的、可重用指南（例如，批评代理的更新规则或报告代理的细化上下文）。

下图是合规性指南示例多代理工作流程:
![合规性指南示例多代理工作流程](https://github.com/HauUhang/Agents/blob/main/img/workflow.png?raw=true)

例如，如果人类专家标记某些家庭统计必须匿名化，学习代理记录此更正。下次生成类似报告时，批评代理将自动应用这个新规则，减少人类干预的需求。这个批评、人类反馈和泛化的循环允许系统自治适应演变的合规要求<sup>44</sup>。

## 模拟和代理健身房 - 下一个前沿
我们呈现的设计模式可以分类为在线学习，其中代理需要使用它们被工程化的资源和设计模式学习。现在正在研究更先进的方法，其中有一个专用平台，工程化用于在离线过程中优化多代理系统，具有先进的工具和能力，这些不是多代理运行时环境的一部分。这种[代理健身房](https://arxiv.org/abs/2502.14499)<sup>45</sup>的关键属性是：
1. 它不在执行路径中。它是一个独立的离线生产平台，因此可以有任何LM模型的协助、离线工具、云应用程序等。
2. 它提供模拟环境，因此代理可以在新数据上“锻炼”并学习。这个模拟环境对于带有许多优化路径的“试错”优秀。
3. 它可以调用高级合成数据生成器，这些生成器指导模拟尽可能真实，并压力测试代理（这可以包括高级技术，如红队、动态评估和批评代理家族）。
4. 优化工具的军火库不是固定的，它可以采用新工具（通过像MCP或A2A这样的开放协议），或在更高级设置中 - 学习新概念并围绕它们制作工具。
5. 最后，即使像代理健身房这样的结构，也可能无法克服某些边缘案例（由于企业中著名的“部落知识”问题）。在这些情况下，我们看到代理健身房能够连接到领域专家的人类结构，并咨询他们正确的输出集来指导下一组优化。

# 高级Agent示例
## Google联合科学家
联合科学家是一个高级AI Agent，设计为虚拟研究合作者，通过系统探索复杂问题空间加速科学发现。它使研究人员能够定义目标、在指定的公共和专有知识来源中扎根代理，然后生成并评估新型假设景观。

为了实现这一点，联合科学家催生整个代理生态系统彼此协作。
![人工智能合作科学家设计系统](https://github.com/HauUhang/Agents/blob/main/img/AI_co-scientist.png?raw=true)

将系统视为研究项目经理。AI首先采取广泛的研究目标并创建详细的项目计划。然后一个“监督者”代理充当经理，将任务委托给专业代理团队，并分配资源如计算能力。这种结构确保项目可以轻松扩展，并且团队的方法在他们向最终目标工作时改进。
![合作科学家多智能体工作流程](https://github.com/HauUhang/Agents/blob/main/img/Co-scientist.png?raw=true)

各种代理工作数小时，甚至数天，并不断改进生成的假设，运行循环和元循环，不仅改进生成的idea，还改进我们判断和创建新idea的方式。

## AlphaEvolve代理
另一个高级代理示例是AlphaEvolve，一个AI代理，发现并优化数学和计算机科学中复杂问题的算法。

AlphaEvolve通过结合我们Gemini语言模型的创意代码生成与自动化评估系统工作。它使用进化过程：AI生成潜在解决方案，评估者评分它们，最有前景的想法用作下一代代码的灵感。

这种方法已经导致重大突破，包括：
* 改善Google数据中心、芯片设计和AI训练的效率。
* 发现更快的矩阵乘法算法。
* 找到开放数学问题的新解决方案。

AlphaEvolve擅长验证解决方案质量远比首先找到它更容易的问题。
![Alpha Evolve 设计系统](https://github.com/HauUhang/Agents/blob/main/img/Alpha_Evolve.png?raw=true)

AlphaEvolve设计用于人类和AI之间的深度、迭代伙伴关系。这种协作以两种主要方式工作：
* **透明解决方案**： AI生成解决方案作为人类可读代码。这种透明允许用户理解逻辑、获得洞见、信任结果，并直接修改代码以满足他们的需求。
* **专家指导**： 人类专业知识对于定义问题至关重要。用户通过细化评估指标和指导探索来指导AI，这防止系统利用问题定义中的无意漏洞。这个交互循环确保最终解决方案既强大又实用。

代理的结果是代码的持续改进，不断改进人类指定的指标。
![算法演化](https://github.com/HauUhang/Agents/blob/main/img/Algorithm_evolution.png?raw=true)

# 结论
生成式AI代理标志着一个关键演变，将人工智能从内容创建的被动工具转变为问题解决的主动、自治伙伴。本文档提供了理解和构建这些系统的正式框架，超越原型，建立可靠、生产级的架构。

我们已将代理解构为其三个基本组件：推理**模型**（“大脑”）、可操作**工具**（“双手”），以及治理**协调层**（“神经系统”）。这些部分的无缝集成，在连续“思考、行动、观察”循环中运行，解锁代理的真正潜力。通过分类代理系统——从1级连接问题解决者到3级协作多代理系统——架构师和产品领导者现在可以战略性地界定他们的雄心，以匹配任务的复杂性。

中央挑战和机会在于新的开发人员范式。我们不再只是定义明确逻辑的“砖瓦工”；我们是必须指导、约束和调试自治实体的“架构师”和“导演”。使LM如此强大的灵活性也是其不可靠性的来源。因此，成功不是仅在初始提示中找到，而是在整个系统应用的工程严谨性中：在鲁棒工具合同、弹性错误处理、复杂上下文管理和全面评估中。

这里概述的原则和架构模式作为基础蓝图。它们是导航这个软件新前沿的指南针，使我们能够构建不仅仅是“工作流自动化”，而是真正协作、有能力且适应性的新团队成员。随着这项技术成熟，这种纪律化的、架构方法将是利用代理AI全部力量的决定因素。

#参考文献
1. Julia Wiesinger, Patrick Marlow, et al. 2024 “Agents”.  
Available at: https://www.kaggle.com/whitepaper-agents.
2. Antonio Gulli, Lavi Nigam, et al. 2025 “Agents Companion”.  
Available at: https://www.kaggle.com/whitepaper-agent-companion.
3. Shunyu Yao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'.  
Available at: https://arxiv.org/abs/2210.03629.
4. Wei, J., Wang, X. et al., 2023, 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'.  
Available at: https://arxiv.org/pdf/2201.11903.pdf.
5. Shunyu Yao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'.  
Available at: https://arxiv.org/abs/2210.03629.
6. https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018
7. Shunyu Yao, et. al., 2024, ‘τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains’,  
Available at: https://arxiv.org/abs/2406.12045.
8. https://artificialanalysis.ai/guide
9. https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/vertex-ai-model-optimizer
10. https://gemini.google/overview/gemini-live/
11. https://cloud.google.com/vision?e=48754805&hl=en
12. https://cloud.google.com/speech-to-text?e=48754805&hl=en
13. https://medium.com/google-cloud/genaiops-operationalize-generative-ai-apractical-guide-d5bedaa59d78
14. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/code-execution/overview
15. https://ai.google.dev/gemini-api/docs/function-calling
16. https://github.com/modelcontextprotocol/
17. https://ai.google.dev/gemini-api/docs/google-search
18. https://google.github.io/adk-docs/
19. https://google.github.io/adk-docs/sessions/memory/
20. https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system
21. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview
22. https://cloud.google.com/kubernetes-engine/docs/concepts/gke-and-cloud-run
23. https://github.com/GoogleCloudPlatform/agent-starter-pack
24. Sokratis Kartakis, 2024, ‘GenAI in Production: MLOps or GenAIOps?’.  
Available at: https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0.
25. Guangya Liu, Sujay Solomon, March 2025 “AI Agent Observability - Evolving Standards and Best Practice”.  
Available at: https://opentelemetry.io/blog/2025/ai-agent-observability/.
26. https://discuss.google.dev/t/agents-are-not-tools/192812
27. Damien Masson et. al, 2024, ‘DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models’.  
Available at: https://arxiv.org/abs/2310.03691.
28. MCP UI is a system of controlling UI via MCP tools https://mcpui.dev/.
29. AG UI is a protocol of controlling UI via event passing and optionally shared state https://ag-ui.com/.
30. A2UI is a protocol of generating UI via structured output and A2A message
passing https://github.com/google/A2UI.
31. https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api.
32. https://saif.google/focus-on-agents.
33. https://simonwillison.net/series/prompt-injection/.
34. https://storage.googleapis.com/gweb-research2023-media/pubtools/1018686.pdf.
35. https://spiffe.io/.
36. https://openreview.net/pdf?id=l9rATNBB8Y.
37. https://google.github.io/adk-docs/safety/.
38. https://google.github.io/adk-docs/callbacks/design-patterns-and-best-practices
/#guardrails-policy-enforcement
39. TKTK
40. https://cloud.google.com/security-command-center/docs/model-armor-overview
41. https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview
42. https://cloud.google.com/run/sla
43. https://github.com/CharlesQ9/Self-Evolving-Agents
44. Juraj Gottweis, et. al., 2025, ‘Accelerating scientific breakthroughs with an AI co-scientist’.  
Available at: https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/.
45. Deepak Nathani et. al. 2025, ‘MLGym: A New Framework and Benchmark for Advancing AI Research Agents’,  
Available at: https://arxiv.org/abs/2502.14499.